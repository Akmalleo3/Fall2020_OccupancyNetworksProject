{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Encoder network for single view 3D reconstruction is a ResNet18 pretrained\n",
    "#on the ImageNet dataset with the last fully-connected layer adjusted to project\n",
    "#the features to a 256 dimensional embedding, \"c\"\n",
    "from torchvision.models.resnet import resnet18 as _resnet18\n",
    "import numpy\n",
    "from PIL import Image\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageEncoder,self).__init__()\n",
    "        self.encoderModel = _resnet18(pretrained=True)\n",
    "        self.fc1 = nn.Linear(1000, 256)\n",
    "        self.betafc = nn.Linear(256,256)\n",
    "        self.gammafc = nn.Linear(256,256)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.encoderModel(x)\n",
    "        #project to 256 dimensional embedding \n",
    "        x = self.fc1(x)\n",
    "        # Obtain Beta and gamma inputs into conditional batch normalization\n",
    "        # QUESTION Are these split or one after the other?\n",
    "        beta = self.betafc(x)\n",
    "        gamma = self.gammafc(x) #? gammaLayer(beta)\n",
    "        return beta,gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Block,self).__init__()\n",
    "        self.fc1 = nn.Linear(256,256)\n",
    "        self.fc2 = nn.Linear(256,256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "\n",
    "        \n",
    "    def forward(self,y):\n",
    "        x = y['ex']\n",
    "        gamma = y['gamma']\n",
    "        beta = y['beta']\n",
    "        #First apply Conditional Batch Normalization\n",
    "        out = gamma*self.bn1(x) + beta\n",
    "        #Then ReLU activation function\n",
    "        out = F.relu(out)\n",
    "        #fully connected layer\n",
    "        out = self.fc1(out)\n",
    "        #Second CBN layer\n",
    "        out = gamma*self.bn2(out) + beta\n",
    "        #RELU activation\n",
    "        out = F.relu(out)\n",
    "        #2nd fully connected\n",
    "        out = self.fc2(out)\n",
    "        #Add to the input of the ResNet Block \n",
    "        out = x + out\n",
    "        \n",
    "        return {'ex':out, 'beta':beta, 'gamma':gamma}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OccupancyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OccupancyModel,self).__init__()\n",
    "        self.blocks = self.makeBlocks()\n",
    "        self.encoder = ImageEncoder()\n",
    "        self.cbn = nn.BatchNorm1d(256)\n",
    "        self.fc1 = nn.Linear(3,256)\n",
    "        self.fc2 = nn.Linear(256,1)\n",
    "        \n",
    "    def makeBlocks(self):\n",
    "        blocks = []\n",
    "        for _ in range(5):\n",
    "            blocks.append(Block())\n",
    "        return nn.Sequential(*blocks)\n",
    "   \n",
    "  \n",
    "    def forward(self,x,img):\n",
    "        gamma,beta = self.encoder(img)\n",
    "        x = self.fc1(x)\n",
    "        #5 pre-activation ResNet-blocks\n",
    "        x = self.blocks({'gamma':gamma, 'beta':beta, 'ex':x })\n",
    "        x = x['ex']\n",
    "        x = gamma*self.cbn(x) + beta\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OccupancyModel()\n",
    "#Input to the occupancy network architecture is the \n",
    "#output of the encoder network and a batch of 3D coordinates. \n",
    "coords = torch.rand(64,3)\n",
    "image = torch.rand(64,3,7,7)\n",
    "model.eval()\n",
    "\n",
    "p = model(coords,image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load some data:\n",
    "#The .npz contains \"points, occupancies, loc, scale\" \n",
    "with numpy.load(\"/home/andrea/Documents/GradSchool/OccupancyNetworks/occupancy_networks/data/ShapeNet/02691156/fd528602cbde6f11bbf3143b1cb6076a/points.npz\") as data:\n",
    "    pts = torch.tensor(data[\"points\"], dtype=torch.float)\n",
    "    occupancies = torch.tensor(numpy.unpackbits(data[\"occupancies\"])[:pts.size()[0]], dtype=torch.float)\n",
    "\n",
    "image = numpy.array(Image.open(\"/home/andrea/Documents/GradSchool/OccupancyNetworks/occupancy_networks/data/ShapeNet/02691156/fd528602cbde6f11bbf3143b1cb6076a/img_choy2016/015.jpg\"))\n",
    "#At least for this image directory, the jpgs come in as 137,137,3\n",
    "image = torch.tensor(image,dtype=torch.float).permute(2,0,1)\n",
    "image = image.view(1,3,137,137)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(list(zip(pts,occupancies)), batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, trainloader, optimizer):\n",
    "    modelCriterion = nn.BCELoss()\n",
    "    model.train()\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        (images, pts, occupancies) = data\n",
    "        print(\"in train\")\n",
    "        print(images.size())\n",
    "        print(pts.size())\n",
    "        print(occupancies.size())\n",
    "        optimizer.zero_grad()\n",
    "        output = model(pts, images[0][4].reshape(1,3,137,137)) #a probability for each point \n",
    "        loss = modelCriterion(output, occupancies)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset), 100. * batch_idx / len(train_loader),\n",
    "                loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/100000 (0%)]\\tLoss: 0.001071\n",
      "Train Epoch: 1 [20/100000 (1%)]\\tLoss: 0.000012\n",
      "Train Epoch: 1 [40/100000 (1%)]\\tLoss: 0.003240\n",
      "Train Epoch: 1 [60/100000 (2%)]\\tLoss: 0.009982\n",
      "Train Epoch: 1 [80/100000 (3%)]\\tLoss: 0.064105\n",
      "Train Epoch: 1 [100/100000 (3%)]\\tLoss: 0.040212\n",
      "Train Epoch: 1 [120/100000 (4%)]\\tLoss: 0.003784\n",
      "Train Epoch: 1 [140/100000 (4%)]\\tLoss: 0.092932\n",
      "Train Epoch: 1 [160/100000 (5%)]\\tLoss: 0.008418\n",
      "Train Epoch: 1 [180/100000 (6%)]\\tLoss: 0.008762\n",
      "Train Epoch: 1 [200/100000 (6%)]\\tLoss: 0.048621\n",
      "Train Epoch: 1 [220/100000 (7%)]\\tLoss: 0.004228\n",
      "Train Epoch: 1 [240/100000 (8%)]\\tLoss: 0.006790\n",
      "Train Epoch: 1 [260/100000 (8%)]\\tLoss: 0.004797\n",
      "Train Epoch: 1 [280/100000 (9%)]\\tLoss: 0.041292\n",
      "Train Epoch: 1 [300/100000 (10%)]\\tLoss: 0.067860\n",
      "Train Epoch: 1 [320/100000 (10%)]\\tLoss: 0.004231\n",
      "Train Epoch: 1 [340/100000 (11%)]\\tLoss: 0.002475\n",
      "Train Epoch: 1 [360/100000 (12%)]\\tLoss: 0.107249\n",
      "Train Epoch: 1 [380/100000 (12%)]\\tLoss: 0.012398\n",
      "Train Epoch: 1 [400/100000 (13%)]\\tLoss: 0.001745\n",
      "Train Epoch: 1 [420/100000 (13%)]\\tLoss: 0.008754\n",
      "Train Epoch: 1 [440/100000 (14%)]\\tLoss: 0.002487\n",
      "Train Epoch: 1 [460/100000 (15%)]\\tLoss: 0.009591\n",
      "Train Epoch: 1 [480/100000 (15%)]\\tLoss: 0.259473\n",
      "Train Epoch: 1 [500/100000 (16%)]\\tLoss: 0.055811\n",
      "Train Epoch: 1 [520/100000 (17%)]\\tLoss: 0.004108\n",
      "Train Epoch: 1 [540/100000 (17%)]\\tLoss: 0.001634\n",
      "Train Epoch: 1 [560/100000 (18%)]\\tLoss: 0.003418\n",
      "Train Epoch: 1 [580/100000 (19%)]\\tLoss: 0.007292\n",
      "Train Epoch: 1 [600/100000 (19%)]\\tLoss: 0.034900\n",
      "Train Epoch: 1 [620/100000 (20%)]\\tLoss: 0.012758\n",
      "Train Epoch: 1 [640/100000 (20%)]\\tLoss: 0.044486\n",
      "Train Epoch: 1 [660/100000 (21%)]\\tLoss: 0.077938\n",
      "Train Epoch: 1 [680/100000 (22%)]\\tLoss: 0.004699\n",
      "Train Epoch: 1 [700/100000 (22%)]\\tLoss: 0.012657\n",
      "Train Epoch: 1 [720/100000 (23%)]\\tLoss: 0.032651\n",
      "Train Epoch: 1 [740/100000 (24%)]\\tLoss: 0.006407\n",
      "Train Epoch: 1 [760/100000 (24%)]\\tLoss: 0.006875\n",
      "Train Epoch: 1 [780/100000 (25%)]\\tLoss: 0.001233\n",
      "Train Epoch: 1 [800/100000 (26%)]\\tLoss: 0.021830\n",
      "Train Epoch: 1 [820/100000 (26%)]\\tLoss: 0.002186\n",
      "Train Epoch: 1 [840/100000 (27%)]\\tLoss: 0.004379\n",
      "Train Epoch: 1 [860/100000 (28%)]\\tLoss: 0.001906\n",
      "Train Epoch: 1 [880/100000 (28%)]\\tLoss: 0.000785\n",
      "Train Epoch: 1 [900/100000 (29%)]\\tLoss: 0.003615\n",
      "Train Epoch: 1 [920/100000 (29%)]\\tLoss: 0.000574\n",
      "Train Epoch: 1 [940/100000 (30%)]\\tLoss: 0.103653\n",
      "Train Epoch: 1 [960/100000 (31%)]\\tLoss: 0.001334\n",
      "Train Epoch: 1 [980/100000 (31%)]\\tLoss: 0.008814\n",
      "Train Epoch: 1 [1000/100000 (32%)]\\tLoss: 0.001281\n",
      "Train Epoch: 1 [1020/100000 (33%)]\\tLoss: 0.005556\n",
      "Train Epoch: 1 [1040/100000 (33%)]\\tLoss: 0.011805\n",
      "Train Epoch: 1 [1060/100000 (34%)]\\tLoss: 0.002063\n",
      "Train Epoch: 1 [1080/100000 (35%)]\\tLoss: 0.049691\n",
      "Train Epoch: 1 [1100/100000 (35%)]\\tLoss: 0.004002\n",
      "Train Epoch: 1 [1120/100000 (36%)]\\tLoss: 0.001287\n",
      "Train Epoch: 1 [1140/100000 (36%)]\\tLoss: 0.029785\n",
      "Train Epoch: 1 [1160/100000 (37%)]\\tLoss: 0.070618\n",
      "Train Epoch: 1 [1180/100000 (38%)]\\tLoss: 0.004665\n",
      "Train Epoch: 1 [1200/100000 (38%)]\\tLoss: 0.077540\n",
      "Train Epoch: 1 [1220/100000 (39%)]\\tLoss: 0.011522\n",
      "Train Epoch: 1 [1240/100000 (40%)]\\tLoss: 0.057934\n",
      "Train Epoch: 1 [1260/100000 (40%)]\\tLoss: 0.009068\n",
      "Train Epoch: 1 [1280/100000 (41%)]\\tLoss: 0.004182\n",
      "Train Epoch: 1 [1300/100000 (42%)]\\tLoss: 0.067807\n",
      "Train Epoch: 1 [1320/100000 (42%)]\\tLoss: 0.008078\n",
      "Train Epoch: 1 [1340/100000 (43%)]\\tLoss: 0.015752\n",
      "Train Epoch: 1 [1360/100000 (44%)]\\tLoss: 0.005867\n",
      "Train Epoch: 1 [1380/100000 (44%)]\\tLoss: 0.002049\n",
      "Train Epoch: 1 [1400/100000 (45%)]\\tLoss: 0.006065\n",
      "Train Epoch: 1 [1420/100000 (45%)]\\tLoss: 0.041379\n",
      "Train Epoch: 1 [1440/100000 (46%)]\\tLoss: 0.007449\n",
      "Train Epoch: 1 [1460/100000 (47%)]\\tLoss: 0.139569\n",
      "Train Epoch: 1 [1480/100000 (47%)]\\tLoss: 0.049375\n",
      "Train Epoch: 1 [1500/100000 (48%)]\\tLoss: 0.052159\n",
      "Train Epoch: 1 [1520/100000 (49%)]\\tLoss: 0.006857\n",
      "Train Epoch: 1 [1540/100000 (49%)]\\tLoss: 0.004502\n",
      "Train Epoch: 1 [1560/100000 (50%)]\\tLoss: 0.002909\n",
      "Train Epoch: 1 [1580/100000 (51%)]\\tLoss: 0.007757\n",
      "Train Epoch: 1 [1600/100000 (51%)]\\tLoss: 0.008882\n",
      "Train Epoch: 1 [1620/100000 (52%)]\\tLoss: 0.003523\n",
      "Train Epoch: 1 [1640/100000 (52%)]\\tLoss: 0.000791\n",
      "Train Epoch: 1 [1660/100000 (53%)]\\tLoss: 0.055691\n",
      "Train Epoch: 1 [1680/100000 (54%)]\\tLoss: 0.006886\n",
      "Train Epoch: 1 [1700/100000 (54%)]\\tLoss: 0.001421\n",
      "Train Epoch: 1 [1720/100000 (55%)]\\tLoss: 0.041570\n",
      "Train Epoch: 1 [1740/100000 (56%)]\\tLoss: 0.004254\n",
      "Train Epoch: 1 [1760/100000 (56%)]\\tLoss: 0.044388\n",
      "Train Epoch: 1 [1780/100000 (57%)]\\tLoss: 0.104399\n",
      "Train Epoch: 1 [1800/100000 (58%)]\\tLoss: 0.003545\n",
      "Train Epoch: 1 [1820/100000 (58%)]\\tLoss: 0.003390\n",
      "Train Epoch: 1 [1840/100000 (59%)]\\tLoss: 0.072325\n",
      "Train Epoch: 1 [1860/100000 (60%)]\\tLoss: 0.061694\n",
      "Train Epoch: 1 [1880/100000 (60%)]\\tLoss: 0.003211\n",
      "Train Epoch: 1 [1900/100000 (61%)]\\tLoss: 0.012251\n",
      "Train Epoch: 1 [1920/100000 (61%)]\\tLoss: 0.024698\n",
      "Train Epoch: 1 [1940/100000 (62%)]\\tLoss: 0.097152\n",
      "Train Epoch: 1 [1960/100000 (63%)]\\tLoss: 0.004367\n",
      "Train Epoch: 1 [1980/100000 (63%)]\\tLoss: 0.027747\n",
      "Train Epoch: 1 [2000/100000 (64%)]\\tLoss: 0.085205\n",
      "Train Epoch: 1 [2020/100000 (65%)]\\tLoss: 0.007062\n",
      "Train Epoch: 1 [2040/100000 (65%)]\\tLoss: 0.011896\n",
      "Train Epoch: 1 [2060/100000 (66%)]\\tLoss: 0.155226\n",
      "Train Epoch: 1 [2080/100000 (67%)]\\tLoss: 0.003218\n",
      "Train Epoch: 1 [2100/100000 (67%)]\\tLoss: 0.004201\n",
      "Train Epoch: 1 [2120/100000 (68%)]\\tLoss: 0.029313\n",
      "Train Epoch: 1 [2140/100000 (68%)]\\tLoss: 0.005776\n",
      "Train Epoch: 1 [2160/100000 (69%)]\\tLoss: 0.051252\n",
      "Train Epoch: 1 [2180/100000 (70%)]\\tLoss: 0.000532\n",
      "Train Epoch: 1 [2200/100000 (70%)]\\tLoss: 0.055981\n",
      "Train Epoch: 1 [2220/100000 (71%)]\\tLoss: 0.002558\n",
      "Train Epoch: 1 [2240/100000 (72%)]\\tLoss: 0.040132\n",
      "Train Epoch: 1 [2260/100000 (72%)]\\tLoss: 0.001443\n",
      "Train Epoch: 1 [2280/100000 (73%)]\\tLoss: 0.000802\n",
      "Train Epoch: 1 [2300/100000 (74%)]\\tLoss: 0.000861\n",
      "Train Epoch: 1 [2320/100000 (74%)]\\tLoss: 0.000510\n",
      "Train Epoch: 1 [2340/100000 (75%)]\\tLoss: 0.034982\n",
      "Train Epoch: 1 [2360/100000 (75%)]\\tLoss: 0.029609\n",
      "Train Epoch: 1 [2380/100000 (76%)]\\tLoss: 0.004929\n",
      "Train Epoch: 1 [2400/100000 (77%)]\\tLoss: 0.055278\n",
      "Train Epoch: 1 [2420/100000 (77%)]\\tLoss: 0.073763\n",
      "Train Epoch: 1 [2440/100000 (78%)]\\tLoss: 0.001088\n",
      "Train Epoch: 1 [2460/100000 (79%)]\\tLoss: 0.005650\n",
      "Train Epoch: 1 [2480/100000 (79%)]\\tLoss: 0.036014\n",
      "Train Epoch: 1 [2500/100000 (80%)]\\tLoss: 0.003484\n",
      "Train Epoch: 1 [2520/100000 (81%)]\\tLoss: 0.162931\n",
      "Train Epoch: 1 [2540/100000 (81%)]\\tLoss: 0.005947\n",
      "Train Epoch: 1 [2560/100000 (82%)]\\tLoss: 0.004219\n",
      "Train Epoch: 1 [2580/100000 (83%)]\\tLoss: 0.004080\n",
      "Train Epoch: 1 [2600/100000 (83%)]\\tLoss: 0.003312\n",
      "Train Epoch: 1 [2620/100000 (84%)]\\tLoss: 0.002020\n",
      "Train Epoch: 1 [2640/100000 (84%)]\\tLoss: 0.058110\n",
      "Train Epoch: 1 [2660/100000 (85%)]\\tLoss: 0.050332\n",
      "Train Epoch: 1 [2680/100000 (86%)]\\tLoss: 0.005551\n",
      "Train Epoch: 1 [2700/100000 (86%)]\\tLoss: 0.044158\n",
      "Train Epoch: 1 [2720/100000 (87%)]\\tLoss: 0.067146\n",
      "Train Epoch: 1 [2740/100000 (88%)]\\tLoss: 0.003027\n",
      "Train Epoch: 1 [2760/100000 (88%)]\\tLoss: 0.002636\n",
      "Train Epoch: 1 [2780/100000 (89%)]\\tLoss: 0.006965\n",
      "Train Epoch: 1 [2800/100000 (90%)]\\tLoss: 0.003303\n",
      "Train Epoch: 1 [2820/100000 (90%)]\\tLoss: 0.006492\n",
      "Train Epoch: 1 [2840/100000 (91%)]\\tLoss: 0.036916\n",
      "Train Epoch: 1 [2860/100000 (91%)]\\tLoss: 0.004562\n",
      "Train Epoch: 1 [2880/100000 (92%)]\\tLoss: 0.002047\n",
      "Train Epoch: 1 [2900/100000 (93%)]\\tLoss: 0.047970\n",
      "Train Epoch: 1 [2920/100000 (93%)]\\tLoss: 0.008339\n",
      "Train Epoch: 1 [2940/100000 (94%)]\\tLoss: 0.060805\n",
      "Train Epoch: 1 [2960/100000 (95%)]\\tLoss: 0.025817\n",
      "Train Epoch: 1 [2980/100000 (95%)]\\tLoss: 0.052844\n",
      "Train Epoch: 1 [3000/100000 (96%)]\\tLoss: 0.004022\n",
      "Train Epoch: 1 [3020/100000 (97%)]\\tLoss: 0.038221\n",
      "Train Epoch: 1 [3040/100000 (97%)]\\tLoss: 0.008448\n",
      "Train Epoch: 1 [3060/100000 (98%)]\\tLoss: 0.000723\n",
      "Train Epoch: 1 [3080/100000 (99%)]\\tLoss: 0.006203\n",
      "Train Epoch: 1 [3100/100000 (99%)]\\tLoss: 0.001179\n",
      "Train Epoch: 1 [3120/100000 (100%)]\\tLoss: 0.000725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrea/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = 0.0001)\n",
    "train(1,model,train_loader,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose a category and load all of the available data:\n",
    "#\"name:table, id: 04379243\"\n",
    "import io\n",
    "topdir = \"/home/andrea/Documents/GradSchool/OccupancyNetworks/occupancy_networks\"\n",
    "imageFiles = [\"000.jpg\",\"001.jpg\", \"002.jpg\",\"003.jpg\", \"004.jpg\", \"005.jpg\", \"006.jpg\", \"007.jpg\", \"008.jpg\",\n",
    "             \"009.jpg\", \"010.jpg\", \"011.jpg\", \"012.jpg\", \"013.jpg\", \"014.jpg\", \"015.jpg\", \"016.jpg\", \"017.jpg\",\n",
    "             \"018.jpg\", \"019.jpg\", \"020.jpg\", \"023.jpg\"]\n",
    "class DataSetClass(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.trainingDirs = []\n",
    "        \n",
    "        #catalogue all of the directories with the chosen category\n",
    "        tablesDirectory=f\"{topdir}/data/ShapeNet/02828884\"\n",
    "        with io.open(f\"{tablesDirectory}/test.lst\") as testlist:\n",
    "            for testdir in testlist.readlines():\n",
    "                self.trainingDirs.append(f\"{tablesDirectory}/{testdir.strip()}\")\n",
    "    def __len__(self):\n",
    "        return len(self.trainingDirs)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        d = self.trainingDirs[idx]\n",
    "        with numpy.load(f\"{d}/points.npz\") as data:\n",
    "            pts = torch.tensor(data[\"points\"], dtype=torch.float)\n",
    "            occupancies = torch.tensor(numpy.unpackbits(data[\"occupancies\"])[:pts.size()[0]], dtype=torch.float)\n",
    "        images = torch.zeros(23,3,137,137)\n",
    "        for idx,imagefile in enumerate(imageFiles):\n",
    "            with Image.open(f\"{d}/img_choy2016/{imagefile}\") as image:\n",
    "                image = numpy.array(image)\n",
    "                image = torch.tensor(image,dtype=torch.float)\n",
    "                #if the image is grey scale, stack 3 to conform dimensions\n",
    "                if len(image.size()) < 3:\n",
    "                    image = torch.stack([image, image, image])\n",
    "                image = image.permute(2,0,1)\n",
    "                image = image.reshape(1,3,137,137)\n",
    "                images[idx] = image\n",
    "        print(images.size())\n",
    "        print(pts.size())\n",
    "        print(occupancies.size())\n",
    "        return images, pts, occupancies\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23, 3, 137, 137])\n",
      "torch.Size([100000, 3])\n",
      "torch.Size([100000])\n",
      "in train\n",
      "torch.Size([1, 23, 3, 137, 137])\n",
      "torch.Size([1, 100000, 3])\n",
      "torch.Size([1, 100000])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "running_mean should contain 100000 elements not 256",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-6e5c588eef64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-2ad607cb7299>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, model, trainloader, optimizer)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moccupancies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m137\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m137\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#a probability for each point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelCriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moccupancies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-8ec2c3b25216>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, img)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m#5 pre-activation ResNet-blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'gamma'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'beta'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ex'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ex'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-96405c293fe1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'beta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#First apply Conditional Batch Normalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;31m#Then ReLU activation function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \"\"\"\n\u001b[0;32m--> 131\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    132\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2012\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2014\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2015\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2016\u001b[0m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: running_mean should contain 100000 elements not 256"
     ]
    }
   ],
   "source": [
    "model = OccupancyModel()\n",
    "data = DataSetClass()\n",
    "train_loader = torch.utils.data.DataLoader(data, batch_size=1)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.0001)\n",
    "\n",
    "train(1,model,train_loader,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
